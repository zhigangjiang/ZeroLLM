import torch
import torch.nn as nn
import torch.nn.functional as F


class MLP(nn.Module):
    def __init__(self, dim: int, hidden_dim: int, multiple_of: int, dropout: float):
        super().__init__()
        # 如果没有指定隐藏层的维度，我们将其设置为输入维度的4倍
        # 然后将其减少到2/3，最后确保它是multiple_of的倍数
        if hidden_dim is None:
            hidden_dim = 4 * dim
            hidden_dim = int(2 * hidden_dim / 3)
            hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)
        # 定义第一层线性变换，从输入维度到隐藏维度
        self.w1 = nn.Linear(dim, hidden_dim, bias=False)
        # 定义第二层线性变换，从隐藏维度到输入维度
        self.w2 = nn.Linear(hidden_dim, dim, bias=False)
        # 定义第三层线性变换，从输入维度到隐藏维度
        self.w3 = nn.Linear(dim, hidden_dim, bias=False)
        # 定义dropout层，用于防止过拟合
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        # 前向传播函数
        # 首先，输入x通过第一层线性变换和SILU激活函数
        # 然后，结果乘以输入x通过第三层线性变换的结果
        # 最后，通过第二层线性变换和dropout层
        # 实干家通道 (w1)：负责对数据进行非线性变换（SiLU(w1(x))），提取特征。
        # 门控通道 (w3)：负责生成一个**“阀门”或“过滤器”**。
        # 相乘操作 (*)：这是元素级乘法（Element-wise product）。w3 的输出决定了 w1 的输出中，哪些信息应该被保留，哪些应该被抑制。
        return self.dropout(self.w2(F.silu(self.w1(x)) * self.w3(x)))

if __name__ == "__main__":
    from config.model_config import ModelConfig
    import math
    args = ModelConfig()

    # 创建MLP实例
    mlp = MLP(args.dim, args.hidden_dim, args.multiple_of, args.dropout)
    # 随机生成数据
    x = torch.randn(1, 50, args.dim)
    # 运行MLP模型
    output = mlp(x)
    print(output.shape)